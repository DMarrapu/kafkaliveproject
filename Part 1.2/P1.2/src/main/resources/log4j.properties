# set global logging severity to INFO (and upwards: WARN, ERROR, FATAL)
#log4j.rootLogger=file, console
log4j.rootCategory=console, file
# console config (restrict only to ERROR and FATAL)
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
#log4j.appender.console.threshold=ERROR
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}.%L: %m%n
# file config
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=logs/ingest.log
log4j.appender.file.MaxFileSize=5MB
log4j.appender.file.MaxBackupIndex=3
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}.%L: %m%n
# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN, file
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR, file
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO, file
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO, file
log4j.logger.org.apache.spark=WARN, file
log4j.logger.org.apache.hadoop=WARN, file
log4j.logger.org.spark-project.jetty=WARN, file
log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR, file
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

#log4j.logger.com.fpcl.ingest=DEBUG, console
log4j.logger.com.fpcl.ingest=DEBUG, file, console
